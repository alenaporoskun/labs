{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T8_1NN_RANDOMFOREST\n",
    "## 1NN ПРОТИ RANDOMFOREST \n",
    "\n",
    "\n",
    "У цьому завданні буде використовуватися датасет **digits з sklearn.datasets**. Залиште останні 25% об'єктів для контролю якості, розділивши **X і y на X_train, y_train і X_test, y_test**.\n",
    "\n",
    "Метою завдання буде реалізувати найпростіший метричний класифікатор - метод найближчого сусіда, а також порівняти якість роботи реалізованого вами 1NN з RandomForestClassifier з sklearn на 1000 деревах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Встановлення найновіших біблотек, щоб не було проблем з числовими відповідями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==0.24.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn==0.24.2) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn==0.24.2) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn==0.24.2) (1.22.4)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn==0.24.2) (1.9.1)\n",
      "Requirement already satisfied: numpy==1.22.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.22.4)\n"
     ]
    }
   ],
   "source": [
    "# Перевірочні дані для лабораторної роботи отримані з використанням таких версій бібліотек \n",
    "!pip install \"scikit-learn == 0.24.2\"\n",
    "!pip install \"numpy == 1.22.4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn 0.24.2\n",
      "numpy 1.22.4\n"
     ]
    }
   ],
   "source": [
    "# Перевірити версії бібліотек можна таким чином (перед цим їх потрібно імпортувати)\n",
    "print('sklearn',sklearn.__version__)\n",
    "print('numpy',np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Завантажуємо необхідні бібліотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Завантажуємо датасет **digits**. Та позначаємо незалежні та залежні змінні."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Розділимо **X і y на X_train, y_train і X_test, y_test**, залишивши останні 25% об'єктів для контролю якості."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index = 1348\n"
     ]
    }
   ],
   "source": [
    "index = round(X.shape[0]*0.75)\n",
    "print('index =', index)\n",
    "\n",
    "X_train, X_test = np.split(X, [index])\n",
    "y_train, y_test = np.split(y, [index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75% = 1348\n",
      "25% = 449\n"
     ]
    }
   ],
   "source": [
    "print('75% =', round(X.shape[0]*0.75))\n",
    "print('25% =', round(X.shape[0]*0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1348, 64)\n",
      "(449, 64)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завдання 1\n",
    "\n",
    "Реалізуйте самостійно метод одного найближчого сусіда з евклідовою метрикою для задачі класифікації. Можна не брати корінь з суми квадратів відхилень, тому що корінь - монотонне перетворення і не впливає на результат роботи алгоритму.\n",
    "\n",
    "Ніякої додаткових перетворень з ознаками в цьому завданні робити не потрібно. Ваша реалізація програми може бути наступною: можна для кожного класифікованого об'єкта складати список пар (відстань до точки з навчальної вибірки, мітка класу в цій точці), потім сортувати цей список (стандартно сортування буде спочатку по першому елементу пари, потім по другому) , а потім брати перший елемент (з найменшою відстанню).\n",
    "\n",
    "Сортування масиву довжиною N вимагає порядку N log N порівнянь (точніше кажучи, вона працює за O (N log N)). Подумайте, як можна легко зменшити час роботи. Крім простого способу знайти найближчий об'єкт за все за N порівнянь, можна спробувати придумати, як розбити простір ознак на частини і зробити структуру даних, яка дозволить швидко шукати сусідів кожної точки. За вибір методу пошуку найближчих сусідів в KNeighborsClassifier з sklearn відповідає параметр algorithm - якщо у вас вже є певний бекграунд в алгоритмах і структурах даних, вам може бути цікаво познайомитися зі структурами даних ball tree і kd tree.\n",
    "\n",
    "**Частка помилок, що допускаються 1NN на тестовій вибірці, – відповідь в завданні 1.\n",
    "Результат округліть до 4-х цифр після коми та запишіть його в відповідну комірку тесту classroom.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_euclid(x, y):\n",
    "    return np.sqrt(np.sum((x - y)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = []\n",
    "for test_x in X_test:\n",
    "    index_min_metric = 0\n",
    "    min_metric = metric_euclid(test_x, X_train[0])\n",
    "    \n",
    "    for index, train_x in enumerate(X_train):\n",
    "        metric = metric_euclid(test_x, train_x)\n",
    "        if (metric < min_metric):\n",
    "            min_metric = metric\n",
    "            index_min_metric = index\n",
    "            \n",
    "    y_pred1.append(y_train[index_min_metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Розрахуємо частку помилок віднявши від 1 таку величину, як *точність(accuracy)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0379\n"
     ]
    }
   ],
   "source": [
    "err_rate1 = 1 - accuracy_score(y_test, y_pred1)\n",
    "ans1 = round(err_rate1, 4) \n",
    "print(ans1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завдання 2\n",
    "\n",
    "Тепер навчіть на навчальній вибірці RandomForestClassifier (n_estimators = 1000) з sklearn. Зробіть прогнози на тестовій вибірці та оцініть частку помилок класифікації на ній. Ця частка помилок - відповідь в завданні 2. Зверніть увагу на те, як співвідноситься якість роботи випадкового лісу з якістю роботи, мабуть, одного з найпростіших методів - 1NN. Така відмінність - особливість даного датасета, але потрібно завжди пам'ятати, що така ситуація теж може мати місце, і не забувати про прості методи.\n",
    "\n",
    "**Результат округліть до 4-х цифр після коми та запишіть його в відповідну комірку тесту classroom.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randforest_clf = RandomForestClassifier(n_estimators = 1000)\n",
    "randforest_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = randforest_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Розрахуємо частку помилок віднявши від 1 таку величину, як *точність(accuracy)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0668\n"
     ]
    }
   ],
   "source": [
    "err_rate2 = 1 - accuracy_score(y_test, y_pred2)\n",
    "ans2 = round(err_rate2, 4) \n",
    "print(ans2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завдання 3\n",
    "\n",
    "Завантажте в classroom створений  Jnotebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
