{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лінійна регресія і стохастичний градієнтний спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Завдання засноване на матеріалах лекцій з лінійної регресії і градиентному спуску. Ви будете прогнозувати виручку компанії в залежності від рівня її інвестицій в рекламу на TV, в газетах і по радіо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ви навчитеся:\n",
    "- вирішувати задачу відновлення лінійної регресії\n",
    "- реалізовувати стохастичний градієнтний спуск для її налаштування\n",
    "- вирішувати задачу лінійної регресії аналітично"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вступ\n",
    "Лінійна регресія - один з найбільш добре вивчених методів машинного навчання, що дозволяє прогнозувати значення кількісної ознаки у вигляді лінійної комбінації інших ознак з параметрами - вагами моделі. Оптимальні (в сенсі мінімальності деякого функціоналу помилки) параметри лінійної регресії можна знайти аналітично за допомогою нормального рівняння або чисельно за допомогою методів оптимізації."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лінійна регресія використовує простий функціонал якості - середньоквадратичну помилку. Ми будемо працювати з вибіркою, що містить 3 ознаки. Для налаштування параметрів (ваг) моделі вирішується наступне завдання:\n",
    "$$\\Large \\frac {1} {\\ell} \\sum_{i = 1} ^ \\ell {{((w_0 + w_1x_{i1} + w_2x_{i2} + w_3x_{i3}) - y_i)} ^ 2 } \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "де $x_{i1}, x_{i2}, x_{i3}$ - значення ознак $i$ -го об'єкта, $y_i$ - значення цільового показника $i$ -го об'єкта, $\\ell$ - число об'єктів в навчальній вибірці."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градієнтний спуск\n",
    "Параметри $w_0, w_1, w_2, w_3$, за якими мінімізується середньоквадратична помилка, можна знаходити чисельно за допомогою градієнтного спуску.\n",
    "Метод найшвидшого крок для ваг буде виглядати наступним чином:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac {2 \\eta} {\\ell} \\sum_{i = 1} ^ \\ell {{((w_0 + w_1x_{i1} + w_2x_{i2} + w_3x_{i3} ) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac {2 \\eta} {\\ell} \\sum_{i = 1} ^ \\ell {{x_{ij} ((w_0 + w_1x_{i1} + w_2x_{i2} + w_3x_{i3}) - y_i)}}, j\\in\\{1,2,3\\}$$\n",
    "Тут $\\eta$ - параметр, крок градієнтного спуску."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастичний градієнтний спуск\n",
    "Проблема градієнтного спуску, описаного вище, в тому, що на великих вибірках вважати на кожному кроці градієнт по всіх наявних даних може бути дуже обчислювально складно.\n",
    "У стохастичною варіанті градієнтного спуску поправки для ваг обчислюються тільки з урахуванням одного випадково взятого об'єкта навчальної вибірки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2 \\eta} {\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} + w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2 \\eta} {\\ell} {x_{kj} ((w_0 + w_1x_{k1} + w_2x_{k2} + w_3x_{k3}) - y_k)}, \\ j \\in \\{1,2,3 \\},$$\n",
    "де $k$ - випадковий індекс, $k \\in \\{1, \\ldots, \\ell \\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальне рівняння\n",
    "Знаходження вектора оптимальних ваг $w$ може бути занайдено і аналітично.\n",
    "Ми хочемо знайти такий вектор ваг $w$, щоб вектор $y$, що наближує цільову ознаку, виходив множенням матриці $X$ (що складається з усіх ознак об'єктів навчальної вибірки, крім цільового) на вектор ваг $w$. Тобто, щоб виконувалося матричне рівняння:\n",
    "$$\\Large y = Xw$$\n",
    "Домноженіем зліва на $X ^ T$ отримуємо:\n",
    "$$\\Large X ^ Ty = X ^ TXw$$\n",
    "Це добре, оскільки тепер матриця $X ^ TX$ - квадратна, і можна знайти рішення (вектор $w$) у вигляді:\n",
    "$$\\Large  {(X ^ TX)} ^ {- 1} X ^ Ty = w$$\n",
    "Матриця ${(X ^ TX)} ^ {- 1} X ^ T$ - [*псевдообернених*] (https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матриці $ X $. У NumPy таку матрицю можна обчислити за допомогою функції [numpy.linalg.pinv] (http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однак, знаходження псевдообернена матриця - операція обчислювально складна і нестабільна в разі малого визначника матриці $X$ (проблема мультиколінеарності).\n",
    "На практиці краще знаходити вектор ваг $w$ рішенням матричного рівняння\n",
    "$$\\Large X ^ TXw = X ^ Ty$$ Це може бути зроблено за допомогою функції [numpy.linalg.solve] (http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/ numpy.linalg.solve.html).\n",
    "\n",
    "Але все ж на практиці для великих матриць $X$ швидше працює градієнтний спуск, особливо його стохастична версія."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Інструкції з виконання"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Завантажте дані з файлу *advertising.csv* в об'єкт pandas DataFrame. [Джерело даних] (http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Подивіться на перші 5 записів і на статистику ознак в цьому наборі даних.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код \n",
    "adver_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200 entries, 1 to 200\n",
      "Data columns (total 4 columns):\n",
      "TV           200 non-null float64\n",
      "Radio        200 non-null float64\n",
      "Newspaper    200 non-null float64\n",
      "Sales        200 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 7.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Ваш код\n",
    "adver_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Створіть масиви NumPy *X* з стовпців TV, Radio і Newspaper і *y* - з колонки Sales. Використовуйте атрибут *values* об'єкта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adver_data.drop('Sales', axis=1).values  # Ваш код \n",
    "y = adver_data['Sales'].values               # Ваш код "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**відмасштабуйте стовпці матриці *X*, вирахувавши з кожного значення середнє за відповідним стовпцем і поділивши результат на стандартне відхилення. Для визначеності, використовуйте методи mean і std векторів NumPy (реалізація std в Pandas може відрізнятися). Зверніть увагу, що в numpy виклик функції .mean () без параметрів повертає середнє по всіх елементах масиву, а не за стовпцями, як в pandas. Щоб зробити обчислення за стовпцями, необхідно вказати параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(X, axis=0)  # Ваш код\n",
    "stds = np.std(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([147.0425,  23.264 ,  30.554 ]),\n",
       " array([85.63933176, 14.80964564, 21.72410606]))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X-means)/stds # Ваш код "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Додайте до матриці *X* стовпець з одиниць, використовуючи методи *hstack*, *ones* і *reshape* бібліотеки NumPy. Вектор з одиниць потрібен для того, щоб не обробляти окремо коефіцієнт $w_0$ лінійної регресії.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.hstack((np.ones((X.shape[0],1)), X)) # Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реалізуйте функцію *mserror* - середньоквадратичну помилку прогнозу. Вона приймає два аргументи - об'єкти Series *y* (значення цільового показника) і *y\\_pred* (передбачені значення). Не використовуйте в цій функції цикли - тоді вона буде обчислювально неефективною.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    # Ваш код \n",
    "    return sum((y-y_pred)**2) / y.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Яка середньоквадратична помилка прогнозу значень Sales, якщо завжди передбачати медіанне значення Sales по вихідній вибірці? Отриманий результат, округлений до 3 знаків після коми, є відповіддю на *'1 завдання'.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.346\n"
     ]
    }
   ],
   "source": [
    "answer1 = mserror(y, np.median(y))  # Ваш код \n",
    "print(round(answer1, 3))\n",
    "def write_answer_1(answer):\n",
    "    answers = [answer]\n",
    "    with open(\"answer_1.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(round(num, 3)) for num in answers]))\n",
    "write_answer_1(answer1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реалізуйте функцію *normal_equation*, яка за заданими матрицями (масивів NumPy) *X* і *y* обчислює вектор ваг $w$ згідно нормальному рівнянню лінійної регресії.**    $ w = {(X ^ TX)} ^ {- 1} X ^ Ty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    return np.dot(np.linalg.pinv(X), y)  # Ваш код "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.0225      3.91925365  2.79206274 -0.02253861]\n"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Які продажу передбачаються лінійної моделлю з вагами, знайденими за допомогою нормального рівняння, в разі середніх інвестицій в рекламу по ТБ, радіо і в газетах? (Тобто при нульових значеннях масштабованих ознак TV, Radio і Newspaper). Отриманий результат, округлений до 3 знаків після коми, є відповіддю на *'2 завдання'*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.022\n"
     ]
    }
   ],
   "source": [
    "answer2 = np.dot(norm_eq_weights, np.mean(X, axis=0)) # Ваш код\n",
    "print(round(answer2, 3))\n",
    "def write_answer_2(answer):\n",
    "    answers = [answer]\n",
    "    with open(\"answer_2.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(round(num, 3)) for num in answers]))\n",
    "write_answer_2(answer2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишіть функцію *linear_prediction*, яка приймає на вхід матрицю *X* і вектор ваг лінійної моделі *w*, а повертає вектор прогнозів у вигляді лінійної комбінації стовпців матриці *X* з вагами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    # Ваш код \n",
    "    return np.dot(X, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Яка середньоквадратична помилка прогнозу значень Sales у вигляді лінійної моделі з вагами, знайденими за допомогою нормального рівняння?\n",
    "Отриманий результат, округлений до 3 знаків після коми, є відповіддю на *'3 завдання'***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.784\n"
     ]
    }
   ],
   "source": [
    "answer3 = mserror(y, linear_prediction(X,norm_eq_weights)) # Ваш код \n",
    "print(round(answer3, 3))\n",
    "def write_answer_3(answer):\n",
    "    answers = [answer]\n",
    "    with open(\"answer_3.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(round(num, 3)) for num in answers]))\n",
    "write_answer_3(answer3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишіть функцію *stochastic_gradient_step*, що реалізує крок стохастичного градієнтного спуску для лінійної регресії. Функція повинна приймати матрицю *X*, вектора *y* і *w*, число *train_ind* - індекс об'єкта навчальної вибірки (рядки матриці *X*), за яким вважається зміна ваг, а також число *$\\eta$* ( eta) - крок градієнтного спуску (за замовчуванням *eta* = 0.01). Результатом буде вектор оновлених ваг. Наша реалізація функції буде явно написана для даних з 3 ознаками, але нескладно модифікувати для будь-якого числа ознак, можете це зробити.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    difference = linear_prediction(X[train_ind],w) - y[train_ind]  # Ваш код \n",
    "    grad0 = difference                          # Ваш код \n",
    "    grad1 = X[train_ind, 1]*difference          # Ваш код \n",
    "    grad2 = X[train_ind, 2]*difference          # Ваш код \n",
    "    grad3 = X[train_ind, 3]*difference          # Ваш код \n",
    "    return  w - eta * np.array([grad0, grad1, grad2, grad3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишіть функцію *stochastic_gradient_descent*, що реалізує стохастический градієнтний спуск для лінійної регресії. Функція приймає на вхід наступні аргументи:**\n",
    "- X - матриця, відповідна навчальній вибірці\n",
    "- y - вектор значень цільового ознаки\n",
    "- w_init - вектор початкових ваг моделі\n",
    "- eta - крок градієнтного спуску (за замовчуванням 0.01)\n",
    "- max_iter - максимальне число ітерацій градієнтного спуску (за замовчуванням 10000)\n",
    "- max_weight_dist - максимальне евклідова відстань між векторами ваг на сусідніх ітераціях градієнтного спуску,\n",
    "при якому алгоритм припиняє роботу (за замовчуванням 1e-8)\n",
    "- seed - число, яке використовується для відтворюваності згенерованих псевдовипадкових чисел (за замовчуванням 42)\n",
    "- verbose - прапор друку інформації (наприклад, для налагодження, за замовчуванням False)\n",
    "\n",
    "**На кожній ітерації в вектор (список) має записуватися поточне значення середньоквадратичної помилки. Функція повинна повертати вектор ваг $w$, а також вектор (список) помилок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent (X, y, w_init, eta = 1e-2, max_iter = 1e4,\n",
    "                                min_weight_dist = 1e-8, seed = 42, verbose = False):\n",
    "    # Ініціалізувавши відстань між векторами ваг на сусідніх\n",
    "    # ітераціях великим числом.\n",
    "    weight_dist = np.inf\n",
    "    # Ініціалізувавши вектор ваг\n",
    "    w = w_init\n",
    "    # Сюди будемо записувати помилки на кожній ітерації\n",
    "    errors = []\n",
    "    # Лічильник ітерацій\n",
    "    iter_num = 0\n",
    "    # Будемо породжувати псевдовипадкові числа\n",
    "    # (Номер об'єкта, який буде змінювати ваги), а для відтворюваності\n",
    "    # цієї послідовності псевдовипадкових чисел використовуємо seed.\n",
    "    np.random.seed (seed)\n",
    "        \n",
    "    # Основний цикл\n",
    "    while weight_dist> min_weight_dist and iter_num <max_iter:\n",
    "        # Породжуємо псевдовипадковий\n",
    "        # індекс об'єкта навчальної вибірки\n",
    "        random_ind = np.random.randint (X.shape [0])\n",
    "        \n",
    "        # Ваш код\n",
    "        #w0 = w\n",
    "        w = stochastic_gradient_step(X, y, w, random_ind, eta)\n",
    "        errors.append(mserror(y, linear_prediction(X,w)))\n",
    "        #weight_dist = np.sqrt(np.dot(w-w0, w-w0))\n",
    "        iter_num = iter_num+1\n",
    "        \n",
    "    if verbose == True:\n",
    "        print(w, errors)\n",
    "    #print(iter_num)\n",
    "    \n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запустіть $10^5$ ітерацій стохастичного градієнтного спуску. Вкажіть вектор початкових ваг *w_init*, що складається з нулів. Залиште параметри *eta* і *seed* рівними їх значенням за замовчуванням (*eta* = 0.01, *seed* = 42 - це важливо для перевірки відповідей).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Ваш код \n",
    "w_init = np.array([0,0,0,0])\n",
    "max_iter = 1e5\n",
    "eta = 0.01\n",
    "ans = stochastic_gradient_descent(X, y, w_init, eta, max_iter)\n",
    "stoch_grad_desc_weights = ans[0]        \n",
    "stoch_errors_by_iter =  ans[1]          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подивимося, чому дорівнює помилка на перших 50 ітераціях стохастичного градієнтного спуску. Бачимо, що помилка не обов'язково зменшується на кожній ітерації.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тепер подивимося на залежність помилки від номера ітерації для $ 10 ^ 5 $ ітерацій стохастичного градієнтного спуску. Бачимо, що алгоритм сходиться.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подивимося на вектор ваг, до якого зійшовся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.00362253,  3.91635318,  3.01061487,  0.11868927])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подивимося на середньоквадратичнепомилку на останній ітерації.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.873944824177364"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Яка середньоквадратична помилка прогнозу значень Sales у вигляді лінійної моделі з вагами, знайденими за допомогою градієнтного спуску? Отриманий результат, округлений до 3 знаків після коми, є відповіддю на *'4 завдання'*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.874\n"
     ]
    }
   ],
   "source": [
    "answer4 = mserror(y, linear_prediction(X,stoch_grad_desc_weights)) # Ваш код \n",
    "print(round(answer4, 3))\n",
    "def write_answer_4(answer):\n",
    "    answers = [answer]\n",
    "    with open(\"answer_4.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(round(num, 3)) for num in answers]))\n",
    "write_answer_4(answer4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завантажте в classroom ваш файл КП02_Прізвище_linreg_stochastic_grad_descent.ipynb та отримані відповіді з файлів answer_1.txt, answer_2.txt, answer_3.txt,answer_4.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
